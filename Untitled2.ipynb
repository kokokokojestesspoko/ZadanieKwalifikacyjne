{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5488ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c33ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filepath to variable for easier access\n",
    "forecast_path = pd.read_csv(r'C:\\Users\\User\\OneDrive\\Pulpit\\zadanie rekrutacyjne\\jena_climate_2009_2016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8b6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 420551 entries, 0 to 420550\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Date Time        420551 non-null  object \n",
      " 1   p (mbar)         420551 non-null  float64\n",
      " 2   T (degC)         420551 non-null  float64\n",
      " 3   Tpot (K)         420551 non-null  float64\n",
      " 4   Tdew (degC)      420551 non-null  float64\n",
      " 5   rh (%)           420551 non-null  float64\n",
      " 6   VPmax (mbar)     420551 non-null  float64\n",
      " 7   VPact (mbar)     420551 non-null  float64\n",
      " 8   VPdef (mbar)     420551 non-null  float64\n",
      " 9   sh (g/kg)        420551 non-null  float64\n",
      " 10  H2OC (mmol/mol)  420551 non-null  float64\n",
      " 11  rho (g/m**3)     420551 non-null  float64\n",
      " 12  wv (m/s)         420551 non-null  float64\n",
      " 13  max. wv (m/s)    420551 non-null  float64\n",
      " 14  wd (deg)         420551 non-null  float64\n",
      "dtypes: float64(14), object(1)\n",
      "memory usage: 48.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# read the data and store data in DataFrame titled prognoza_data\n",
    "forecast_data = forecast_path\n",
    "\n",
    "forecast_data.info();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e499807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2009-01-01 00:10:00\n",
      "1        2009-01-01 00:20:00\n",
      "2        2009-01-01 00:30:00\n",
      "3        2009-01-01 00:40:00\n",
      "4        2009-01-01 00:50:00\n",
      "                 ...        \n",
      "420546   2016-12-31 23:20:00\n",
      "420547   2016-12-31 23:30:00\n",
      "420548   2016-12-31 23:40:00\n",
      "420549   2016-12-31 23:50:00\n",
      "420550   2017-01-01 00:00:00\n",
      "Name: Date Time, Length: 420551, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Date Time ma NIEODPOWIEDNI format, należy go zrzutować na format daty\n",
    "from datetime import datetime, timedelta\n",
    "from pandas import DataFrame\n",
    "\n",
    "forecast_data['Date Time'] = pd.to_datetime(forecast_data['Date Time'],unit='ns')\n",
    "\n",
    "# Podgląd wskazuje, że rzutowanie przebiegło pomyślnie\n",
    "print(forecast_data['Date Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22423aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprawdzanie czy nie ma brakujących danych\n",
    "\n",
    "missing_values_count = forecast_data.isnull().sum()\n",
    "# get the number of missing data points per column\n",
    "missing_values_count[0:len(forecast_data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156fe51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jak widać nie ma brakujących danych, więc nie jest konieczne uzupełnianie zmiennymi bądź usuwanie danych z pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie opisu danych\n",
    "forecast_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretacja Danych\n",
    "# Resultatem describe() jest pokazanie ośmiu liczb dla każdej z oryginalnych kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plik posiada 16 kolumn które przechowują różne wartości fizyczne, niekonieczne niezbędne do stworzenia modelu prognozy pogody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na przykład: Kolumna 'Tpot (K)' jest temperaturą podaną w kelvinach. \n",
    "# Takie dane nie są potrzebne do wyznaczonego modelu, zatem zostaną usunięte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data.drop('Tpot (K)', axis='columns',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d384cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Następnie usuwam dane które mają wysoką kardynalność\n",
    "# wczesniej jednak tworzę kopię obiektu i na nim wykonuję operację\n",
    "\n",
    "forecast_data.drop(columns=['Date Time', 'p (mbar)', 'T (degC)', 'Tdew (degC)','rh (%)', \n",
    "                                 'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
    "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
    "       'wd (deg)'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0493bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tak przygotowane dane można użyć do stworzenia modelu prognozy pogody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustalanie Targetu\n",
    " \n",
    "y = forecast_data['T (degC)']\n",
    "# Ustalanie Feature\n",
    "\n",
    "\n",
    "X = forecast_data[['Date Time', 'p (mbar)', 'T (degC)', 'Tdew (degC)','rh (%)', \n",
    "                                 'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
    "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
    "       'wd (deg)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Split Data do dokładniejszego treningu\n",
    "from sklearn.model_selection import train_test_split\n",
    "# podział danych jest konieczny. Należy podzielić dane na treningowe i validacyjne i na nich osobno stworzyć modele do porównania \n",
    "# MAE\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n",
    "#sprawdzanie czy dane treningowe zgadzają się z danymi validacyjnymi\n",
    "print('train_X: ',train_X.shape)\n",
    "print('val_X: ', val_X.shape)\n",
    "print('train_y: ',train_y.shape)\n",
    "print('val_y: ', val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31052b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc032666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Modelu Random Forest Regressor \n",
    "#import Mean Absolute Error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lm = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression(),\n",
    ")\n",
    "lm.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "\n",
    "#forecast_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "#forecast_model.fit(train_X, train_y)\n",
    "#forecast_predictions = forest_model.predict(val_X)\n",
    "# print(mean_absolute_error(val_y, forecast_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dc8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
